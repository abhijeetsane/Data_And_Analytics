# Major Players

## Observability

- **Data Kin** [https://datakin.com/]
  - Datakin is an end-to-end, real-time data lineage solution that helps you manage everything in your data ecosystem.
  - It observes the movement of data through pipelines, tracing relationships between datasets and making it easier to find, fix, and prevent issues.
  - Datakin automatically traces data lineage, showing your entire data ecosystem in a rich visual graph. It clearly illustrates the upstream and downstream relationships for each dataset.
  - Show data quality metrics and how they change over time so as to determine the anomalies.
  - Can also find a job’s performance in a Gantt-style chart along with its upstream dependencies, making it easy to find bottlenecks.
  
- **Monte Carlo Data** [https://www.montecarlodata.com/]
  - Monte Carlo’s Data Observability Platform is an end-to-end solution for your data stack that monitors and alerts for data issues across your data warehouses, data lakes, ETL, and business intelligence.
  - The platform uses machine learning to infer and learn your data, proactively identify data issues, assess its impact, and notify those who need to know.
  - Can also provides automatic, field-level lineage and centralized data cataloguing that allows teams to better understand the accessibility, location, health, and ownership of their data assets, as well as adhere to strict data governance requirements.
  - Delivers End-to-end observability, ML-powered incident monitoring and resolution, Security-first architecture, Automated data catalog and metadata management, No-code onboarding and provides benefits such as scales to any environment, incident analytics and utilization insights.
  
- **Manta** [https://getmanta.com/]
  - MANTA enables enterprises to achieve end-to-end lineage by providing solutions for parsing complex SQL, ETL programs, business intelligence reports and other kinds of metadata to represent and visualize data lineage.
  - Maps the entire environment to determine what data is stored and where. Carries out instant and accurate impact analyses to accelerate software testing, see how planned changes will influence other parts of the environment, and speed up collaboration between data users.
  - Automates tedious, repetitive tasks to keep your data pipeline healthy—prevent defects with automated impact analyses, speed up incident resolution, reduce the cycle time of data analytics, and increase the value of analytics.
  - Cuts down on manual effort by enabling agile change management with fully-automated impact analysis, incident resolution, and debugging.
  
- **Datafold** [https://www.datafold.com/]
  - Datafold is a data reliability platform focused on proactive data quality management.
  - Automates change management, improve data literacy, achieve compliance, and reduce incident response time.
  - Datafold is accommodated in three parts: Data Diff makes sure that you're in control of the changes to the data pipeline. Don't get fooled by an erroneous transformation, or an unexpected change downstream. Data catalog with column-level lineage gives detailed insight into how the data streams throughout the pipeline, and where reports source their data from. Alerting makes sure that you get notified when something unexpected happens with the data that you base your business-critical decisions on.

- **Databand** [https://databand.ai/]
  - Databand helps you monitor & control your data’s quality, even when you can’t control your sources.It is a proactive data observability platform that isolates data errors as early as data integration and triages issues to alert relevant stakeholders before there's a crisis.  
  - Databand provides visibility into this information by collecting usage and profiling information about your datasets, as well as providing you the ability to custom define data quality metrics that will be sent to Databand's tracking system. In addition, Databand tracks your pipeline metadata, providing granular visibility into data processes so that it is easier to identify issues, enhance team productivity, and optimize performance & costs.
  - Benefits obtained are Connecting and comparing metrics, logs, and traces from all data processes, Instantly streamline analysis of pipelines and health of your system, Accessing alerts and notifications on issues that require immediate attention, Comparing trends on data and code changes to identify the root cause of problems fast, Focuses on optimal code configurations and scheduled data operations.
  - Provides alerts on missing data deliveries, unexpected schema changes, SLA misses, anomalies in column-level statistics like nulls and distributions, irregular data volumes and sizes, pipeline failures, inefficiencies, and errors.
  
- **Acceldata** [https://www.acceldata.io/]
  - Acceldata is known for Multidimensional Data Observability Cloud, helping data-driven enterprises achieve operational excellence, innovation agility, and higher returns on data investment.
  - Acceldata's Data Observability Cloud provides on-demand operational intelligence to support embedded AI and analytics data workloads. With Acceldata, enterprises can easily scale pipelines to meet the needs of modern business, regardless of platform or cloud environment.
  - Acceldata Pulse provides real-time intelligence across all your observability needs.You can build your workflows, and extend alerts for business requirements with algorithmic anomaly detection. Acceldata Pulse also provides recommendations and automation to keep your data systems performant, secure, and reliable.
  - Features provided are Monitor and analyze hundreds of jobs to find outliers, Debug applications efficiently using the entire application history, Reduce MTTR from hours to minutes with advanced root cause analysis and error correlation, Receive custom recommendations tailored for your system, Integrate natively into data engines to extract data, Manage all of your data systems with a powerful Javascript- based dashboard builder.
  
- **MetaPlane** [https://www.metaplane.dev/]
  - Metaplane continuously monitors the data flowing through your data stack then alerts you when something may be going wrong. We do this by collecting metrics, metadata, lineage, and logs, training anomaly detection models on historical values, then sending you alerts for outliers with options to provide model feedback.
  - The Observability platform saves engineering time and increase trust in data by understanding when things break, what went wrong, and how to fix it.
  - Automatically monitors modern data stacks from warehouses to BI dashboards, identifying normal behavior (e.g. lineage, volumes, distributions, freshness), then alerting the right people when things go wrong.
  - Benefits provided by Metaplane are Add tests without writing code, Anomaly detection using historical metadata and Automated warehouse-to-BI lineage.

## Data Quality

- **talend** [https://www.talend.com/]
  - As an integral part of Talend Data Fabric, Data Quality profiles, cleans, and masks data in real time. Machine learning powers recommendations for addressing data quality issues as data flows through your systems.
  - Data profiling lets you quickly identify data quality issues, discover hidden patterns, and spot anomalies through summary statistics and graphical representations. Our built-in Talend Trust Score gives you an immediate, explainable, actionable assessment of confidence, so you know what’s safe to share and which datasets require additional data cleansing.
  - Leverage Talend data health experts to continuously monitor and manage your data at scale. With DQS, you can visualize and track data quality KPIs over time, identify and fix quality issues, and fuel effective business decisions across the organization.
  - Data Quality protects sensitive data with built-in masking, ensuring compliance with internal and external data privacy and data protection regulations.

- **SODA** [https://www.soda.io/]
  - Soda Cloud provides end-to-end observability and control of all your data.
  - Soda SQL and Soda Cloud ensure data quality by squarely addressing the challenges in testing, monitoring, profiling, and gaining observability into your data.
  - Use built-in metrics to define tests in Soda SQL or Soda Cloud that test data against quality thresholds and surface issues that occur throughout your data pipeline. Integrate Soda scans with your existing data orchestration tools to test your data at regular intervals and before or after events such as a transformation.
  - Uses Soda Cloud to monitor and automatically detect anomalies in your data, and to notify your DevOps or Data Quality teams when bad data triggers an alert.

- **BigEye** [https://www.bigeye.com/]
  - Bigeye is an automated data monitoring platform. Bigeye helps analytics and data engineering teams effortlessly monitor the freshness and quality of data at scale. Instant alerts and a no-code interface help the team rapidly detect and respond to data issues before mission critical dashboards and machine learning models are impacted.
  - It helps teams measure, improve, and communicate data quality clearly at any scale.
  - Bigeye enables data teams to detect and proactively resolve data quality and pipeline issues before the business is affected.
  - Dashboard gives data team leaders a high-level view of data health, making it simple to monitor data quality coverage, impact on SLAs, time to resolution, and other key analytics.

- **SuperConductive** [https://www.superconductive.ai/]
  - GreatExpectation : Validating , documentating and profiling your data for maintaining data quality.
  - Declarative language with human readable python methods
  - Does not store data anywhere . Instead it deals in meta data.
  
- **Anomalo** [https://www.anomalo.com/]
  - Complete data quality platform
  - Integrated machine learning
  - Snowflake integration
  - Data quality monitoring
  - Automatically detect and understand extreme events in real world data
  - Unsupervised data monitoring and dynamic data testing
  
- **precisely** [https://www.precisely.com/]
  - Part of the larger Data 360 suite of products.
  - Teams can measure data quality , communicate and collaborate on data across all business levels .
  - Custom data quality scores using configurable data scoring
  - Dashboarding and reporting
  - Discover , verify and cleanse data
  - Improve data quality using Trillium and apply business rules and streamline data governence.

- **lightup** [https://www.lightup.ai/]
  - Main Features
    - Out of box Observability
    - Customizability using SQL
    - Single Click detection
    - Alerting integrations
    - Root Cause Analysis
    - Scheduled Checks
    - CI/CD support
    - Flexible deployment support
    - Security first approach
    - Scalable
  - Data Visibility for all the data assets on dashboard
  - Multiple pre-built connectors available
  - Alerting using ML based anomaly detection

  - **Provides following Data Quality Symptoms**
    - Data availability
      - Ensure tables are updated on time, and data volume is healthy
    - Data conformity
      - Ensure data conforms to the expected format
    - Data validity
      - Ensure data distribution matches expectations
    - Schema changes
      - Track changes in your data as tables and columns get added, removed or changed
  
- **validio** [https://www.validio.io]
  - Data quality validation and monitoring for data at rest in warehouses and data in motion in streams
  -The Validio platform is built to directly eliminate bad data through monitoring, validation and filtering of data in real-time streams and batches.
  - Following modes are supported for data quality and reliability
    - Machine Learning based
    - Statistical test based
    - Rule Based

  - Can work on batch based processing as well as real time data streams.
  - Built in support for high cardinality
  - Non Intrusive as no data is sent outside the environment
  - Customizable alerts
